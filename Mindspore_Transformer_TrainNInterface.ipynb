{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "503bbfa2-41ef-4e22-a276-61a001faea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.185.437 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.193.311 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.201.073 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.209.275 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.217.677 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.233.222 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.244.847 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.252.563 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.260.064 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.268.482 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.276.482 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.286.624 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.299.201 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.307.187 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.314.806 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.322.295 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.328.364 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.340.561 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®é›†å¤§å°: 77919, è¯æ±‡è¡¨å¤§å°: 100070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.352.185 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.362.319 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.370.043 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.379.434 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.387.486 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-19:58:42.400.161 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨¡å‹å‚æ•°é‡: 13108326\n",
      "å¼€å§‹è®­ç»ƒ...\n",
      "Step    0: train loss 11.5175, val loss 11.5174\n",
      "Step   50: train loss 7.0340, val loss 7.4421\n",
      "Step  100: train loss 6.8929, val loss 7.0730\n",
      "Step 100: Loss 6.0790, Grad norm: 1.5225\n",
      "Step  150: train loss 6.4433, val loss 7.1280\n",
      "Step  200: train loss 6.3539, val loss 6.9595\n",
      "Step 200: Loss 6.1801, Grad norm: 1.7230\n",
      "Step  250: train loss 6.2515, val loss 6.7982\n",
      "Step  300: train loss 6.0694, val loss 6.6698\n",
      "Step 300: Loss 6.5072, Grad norm: 2.7139\n",
      "Step  350: train loss 6.1281, val loss 6.8418\n",
      "Step  400: train loss 6.1171, val loss 6.6436\n",
      "Step 400: Loss 5.1911, Grad norm: 4.0618\n",
      "Step  450: train loss 6.0591, val loss 6.6295\n",
      "Step  500: train loss 5.8059, val loss 6.6054\n",
      "Step 500: Loss 5.4950, Grad norm: 3.3147\n",
      "Step  550: train loss 5.8172, val loss 6.7129\n",
      "Step  600: train loss 5.8598, val loss 6.2671\n",
      "Step 600: Loss 5.7146, Grad norm: 3.8601\n",
      "Step  650: train loss 5.7614, val loss 6.4493\n",
      "Step  700: train loss 5.5009, val loss 6.4631\n",
      "Step 700: Loss 6.1680, Grad norm: 5.8212\n",
      "Step  750: train loss 5.7052, val loss 6.3196\n",
      "Step  800: train loss 5.5831, val loss 6.4279\n",
      "Step 800: Loss 5.5329, Grad norm: 7.3148\n",
      "Step  850: train loss 5.4430, val loss 6.3084\n",
      "Step  900: train loss 5.7387, val loss 6.0944\n",
      "Step 900: Loss 5.6838, Grad norm: 4.2086\n",
      "Step  950: train loss 5.4934, val loss 6.2027\n",
      "\n",
      "æœ€ç»ˆç»“æœ: train loss 5.5760, val loss 6.1590\n",
      "æ¨¡å‹å·²ä¿å­˜åˆ° transformer_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "from mindspore import nn, ops, Tensor, Parameter, context\n",
    "import math\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# è®¾ç½®è¿è¡Œæ¨¡å¼å’Œè®¾å¤‡\n",
    "context.set_context(mode=context.PYNATIVE_MODE, device_target=\"CPU\")\n",
    "\n",
    "# è¶…å‚æ•° - è°ƒæ•´äº†å…³é”®å‚æ•°\n",
    "batch_size = 4\n",
    "context_length = 16\n",
    "d_model = 64\n",
    "num_blocks = 4  # å‡å°‘å±‚æ•°\n",
    "num_heads = 4\n",
    "learning_rate = 5e-4  # é™ä½å­¦ä¹ ç‡\n",
    "dropout = 0.1\n",
    "max_iters = 1000\n",
    "eval_interval = 50\n",
    "eval_iters = 20\n",
    "\n",
    "# æ•°æ®åŠ è½½\n",
    "if not os.path.exists('sales_textbook.txt'):\n",
    "    url = 'https://huggingface.co/datasets/goendalf666/sales-textbook_for_convincing_and_selling/raw/main/sales_textbook.txt'\n",
    "    with open('sales_textbook.txt', 'w') as f:\n",
    "        f.write(requests.get(url).text)\n",
    "\n",
    "with open('sales_textbook.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# åˆ†è¯å¤„ç†\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokenized_text = encoding.encode(text)\n",
    "max_token_value = max(tokenized_text) + 1\n",
    "tokenized_text = np.array(tokenized_text, dtype=np.int32)\n",
    "\n",
    "# åˆ’åˆ†æ•°æ®é›†\n",
    "split_idx = int(len(tokenized_text) * 0.9)\n",
    "train_data = tokenized_text[:split_idx]\n",
    "val_data = tokenized_text[split_idx:]\n",
    "\n",
    "print(f\"æ•°æ®é›†å¤§å°: {len(tokenized_text)}, è¯æ±‡è¡¨å¤§å°: {max_token_value}\")\n",
    "\n",
    "class FeedForward(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ffn = nn.SequentialCell(\n",
    "            nn.Dense(d_model, 4 * d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dense(4 * d_model, d_model),\n",
    "            nn.Dropout(keep_prob=1 - dropout)\n",
    "        )\n",
    "    \n",
    "    def construct(self, x):\n",
    "        return self.ffn(x)\n",
    "\n",
    "class Attention(nn.Cell):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "        self.context_length = context_length\n",
    "        \n",
    "        self.key = nn.Dense(d_model, head_size, has_bias=False)\n",
    "        self.query = nn.Dense(d_model, head_size, has_bias=False)\n",
    "        self.value = nn.Dense(d_model, head_size, has_bias=False)\n",
    "        \n",
    "        # ç”Ÿæˆä¸‹ä¸‰è§’æ©ç \n",
    "        mask_np = np.tril(np.ones((context_length, context_length), dtype=np.float32))\n",
    "        self.register_buffer('tril', Tensor(mask_np))\n",
    "        self.dropout = nn.Dropout(keep_prob=1 - dropout)\n",
    "        \n",
    "        self.softmax = nn.Softmax(axis=-1)\n",
    "        self.bmm = ops.BatchMatMul()\n",
    "\n",
    "    def register_buffer(self, name, tensor):\n",
    "        \"\"\"æ¨¡æ‹ŸPyTorchçš„register_bufferåŠŸèƒ½\"\"\"\n",
    "        setattr(self, name, Parameter(tensor, requires_grad=False))\n",
    "\n",
    "    def construct(self, x):\n",
    "        B, T, _ = x.shape\n",
    "        q = self.query(x)  # (B, T, head_size)\n",
    "        k = self.key(x)    # (B, T, head_size)\n",
    "        v = self.value(x)  # (B, T, head_size)\n",
    "\n",
    "        # è®¡ç®—æ³¨æ„åŠ›æƒé‡\n",
    "        att = self.bmm(q, k.swapaxes(-1, -2)) / math.sqrt(self.head_size)  # (B, T, T)\n",
    "\n",
    "        # ä¿®å¤æ©ç å¤„ç†\n",
    "        mask = self.tril[:T, :T]  # (T, T)\n",
    "        mask = ops.expand_dims(mask, 0)  # (1, T, T)\n",
    "        mask = ops.broadcast_to(mask, (B, T, T))  # (B, T, T)\n",
    "        \n",
    "        # ä½¿ç”¨whereè¿›è¡Œæ©ç \n",
    "        att = ops.where(mask == 1.0, att, Tensor(-1e9, att.dtype))\n",
    "\n",
    "        att = self.softmax(att)\n",
    "        att = self.dropout(att)\n",
    "        out = self.bmm(att, v)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Cell):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.CellList([Attention(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Dense(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(keep_prob=1 - dropout)\n",
    "\n",
    "    def construct(self, x):\n",
    "        # æ‰‹åŠ¨æ‹¼æ¥å¤šå¤´è¾“å‡º\n",
    "        head_outputs = []\n",
    "        for head in self.heads:\n",
    "            head_outputs.append(head(x))\n",
    "        out = ops.concat(head_outputs, axis=-1)\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class TransformerBlock(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(head_size=d_model//num_heads)\n",
    "        self.ffn = FeedForward()\n",
    "        self.ln1 = nn.LayerNorm((d_model,), epsilon=1e-5)\n",
    "        self.ln2 = nn.LayerNorm((d_model,), epsilon=1e-5)\n",
    "\n",
    "    def construct(self, x):\n",
    "        # æ®‹å·®è¿æ¥\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.ffn(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class TransformerLanguageModel(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embed = nn.Embedding(max_token_value, d_model)\n",
    "        \n",
    "        # Transformerå—\n",
    "        blocks = []\n",
    "        for _ in range(num_blocks):\n",
    "            blocks.append(TransformerBlock())\n",
    "        blocks.append(nn.LayerNorm((d_model,), epsilon=1e-5))\n",
    "        self.blocks = nn.SequentialCell(*blocks)\n",
    "        \n",
    "        self.lm_head = nn.Dense(d_model, max_token_value)\n",
    "        \n",
    "        # ä½ç½®ç¼–ç \n",
    "        pos_enc = np.zeros((context_length, d_model), dtype=np.float32)\n",
    "        position = np.arange(0, context_length)[:, np.newaxis]\n",
    "        div_term = np.exp(np.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pos_enc[:, 0::2] = np.sin(position * div_term)\n",
    "        pos_enc[:, 1::2] = np.cos(position * div_term)\n",
    "        self.pos_embed = Parameter(Tensor(pos_enc), requires_grad=False)\n",
    "        \n",
    "        # åˆå§‹åŒ–æƒé‡\n",
    "        self.apply_init()\n",
    "\n",
    "    def apply_init(self):\n",
    "        \"\"\"æ”¹è¿›çš„æƒé‡åˆå§‹åŒ–\"\"\"\n",
    "        for _, cell in self.cells_and_names():\n",
    "            if isinstance(cell, nn.Dense):\n",
    "                # Xavieråˆå§‹åŒ–\n",
    "                fan_in = cell.in_channels\n",
    "                fan_out = cell.out_channels\n",
    "                std = math.sqrt(2.0 / (fan_in + fan_out))\n",
    "                # ä½¿ç”¨numpyç”Ÿæˆéšæœºæ•°ç„¶åè½¬æ¢ä¸ºTensor\n",
    "                weight_data = np.random.normal(0, std, cell.weight.shape).astype(np.float32)\n",
    "                cell.weight.set_data(Tensor(weight_data))\n",
    "                if cell.has_bias:\n",
    "                    bias_data = np.zeros(cell.bias.shape).astype(np.float32)\n",
    "                    cell.bias.set_data(Tensor(bias_data))\n",
    "            elif isinstance(cell, nn.Embedding):\n",
    "                # æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–embedding\n",
    "                embed_data = np.random.normal(0, 0.02, cell.embedding_table.shape).astype(np.float32)\n",
    "                cell.embedding_table.set_data(Tensor(embed_data))\n",
    "\n",
    "    def construct(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embed(idx)  # (B,T,C)\n",
    "        \n",
    "        # ä¿®å¤ä½ç½®ç¼–ç \n",
    "        pos_emb = self.pos_embed[:T, :]  # (T, d_model)\n",
    "        pos_emb = ops.expand_dims(pos_emb, 0)  # (1, T, d_model)\n",
    "        pos_emb = ops.broadcast_to(pos_emb, (B, T, d_model))  # (B, T, d_model)\n",
    "        \n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        if targets is not None:\n",
    "            # è®¡ç®—æŸå¤±\n",
    "            B, T, C = logits.shape\n",
    "            logits_flat = logits.view(B * T, C)\n",
    "            targets_flat = targets.view(B * T)\n",
    "            loss_fn = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "            loss = loss_fn(logits_flat, targets_flat)\n",
    "            return logits, loss\n",
    "        return logits, None\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        \"\"\"ç”Ÿæˆæ–‡æœ¬\"\"\"\n",
    "        self.set_train(False)\n",
    "        for _ in range(max_new_tokens):\n",
    "            # æˆªå–æœ€åcontext_lengthä¸ªtoken\n",
    "            idx_cond = idx[:, -context_length:]\n",
    "            logits, _ = self.construct(idx_cond)\n",
    "            logits = logits[:, -1, :]  # åªå–æœ€åä¸€ä¸ªä½ç½®çš„logits\n",
    "            \n",
    "            # æ¸©åº¦é‡‡æ ·\n",
    "            temperature = 0.8\n",
    "            logits = logits / temperature\n",
    "            probs = ops.softmax(logits, axis=-1)\n",
    "            \n",
    "            # ç®€å•çš„top-ké‡‡æ ·ï¼ˆè¿™é‡Œç”¨argmaxä»£æ›¿éšæœºé‡‡æ ·ï¼‰\n",
    "            idx_next = ops.argmax(probs, axis=-1)\n",
    "            idx_next = ops.expand_dims(idx_next, -1)\n",
    "            idx = ops.concat([idx, idx_next], axis=1)\n",
    "        \n",
    "        self.set_train(True)\n",
    "        return idx\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "model = TransformerLanguageModel()\n",
    "total_params = 0\n",
    "for param in model.get_parameters():\n",
    "    if param.requires_grad:\n",
    "        param_size = 1\n",
    "        for dim in param.shape:\n",
    "            param_size *= dim\n",
    "        total_params += param_size\n",
    "print(f\"æ¨¡å‹å‚æ•°é‡: {total_params}\")\n",
    "\n",
    "# æ•°æ®æ‰¹å¤„ç†å‡½æ•°\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    idxs = np.random.randint(0, len(data) - context_length, size=(batch_size,))\n",
    "    x = np.stack([data[i:i+context_length] for i in idxs])\n",
    "    y = np.stack([data[i+1:i+context_length+1] for i in idxs])\n",
    "    return Tensor(x, ms.int32), Tensor(y, ms.int32)\n",
    "\n",
    "# è¯„ä¼°å‡½æ•°\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.set_train(False)\n",
    "    for split in ['train', 'valid']:\n",
    "        losses = []\n",
    "        for _ in range(eval_iters):\n",
    "            x, y = get_batch(split)\n",
    "            _, loss = model(x, y)\n",
    "            losses.append(float(loss.asnumpy()))\n",
    "        out[split] = np.mean(losses)\n",
    "    model.set_train(True)\n",
    "    return out\n",
    "\n",
    "# ä¼˜åŒ–å™¨å’Œæ¢¯åº¦å‡½æ•°\n",
    "optimizer = nn.AdamWeightDecay(model.trainable_params(), \n",
    "                               learning_rate=learning_rate,\n",
    "                               weight_decay=0.01)\n",
    "\n",
    "def forward_fn(x, y):\n",
    "    logits, loss = model(x, y)\n",
    "    return loss\n",
    "\n",
    "grad_fn = ms.value_and_grad(forward_fn, None, optimizer.parameters)\n",
    "\n",
    "# è®­ç»ƒå¾ªç¯\n",
    "print(\"å¼€å§‹è®­ç»ƒ...\")\n",
    "for step in range(max_iters):\n",
    "    # è¯„ä¼°\n",
    "    if step % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"Step {step:4d}: train loss {losses['train']:.4f}, val loss {losses['valid']:.4f}\")\n",
    "    \n",
    "    # è®­ç»ƒæ­¥éª¤\n",
    "    x, y = get_batch('train')\n",
    "    loss, grads = grad_fn(x, y)\n",
    "    optimizer(grads)\n",
    "    \n",
    "    # æ¢¯åº¦æ£€æŸ¥ï¼ˆæ¯100æ­¥æ‰“å°ä¸€æ¬¡ï¼‰\n",
    "    if step % 100 == 0 and step > 0:\n",
    "        grad_norm = 0\n",
    "        for g in grads:\n",
    "            if g is not None:\n",
    "                grad_norm += float(ops.norm(g, ord=2))\n",
    "        print(f\"Step {step}: Loss {float(loss):.4f}, Grad norm: {grad_norm:.4f}\")\n",
    "\n",
    "# æœ€ç»ˆè¯„ä¼°\n",
    "final_losses = estimate_loss()\n",
    "print(f\"\\næœ€ç»ˆç»“æœ: train loss {final_losses['train']:.4f}, val loss {final_losses['valid']:.4f}\")\n",
    "\n",
    "# ä¿å­˜æ¨¡å‹\n",
    "ms.save_checkpoint(model, \"transformer_model.ckpt\")\n",
    "print(\"æ¨¡å‹å·²ä¿å­˜åˆ° transformer_model.ckpt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3300ae-79d4-41dc-9c0b-c907c747936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a93e5bc-d5ac-4e3b-9067-3c3ca99bdade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.844.072 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.854.551 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.862.680 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.870.836 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.877.472 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.890.331 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.902.644 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.910.642 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.918.707 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.926.713 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.934.376 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.945.614 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.957.988 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.966.212 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.974.459 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.982.507 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:22.990.109 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:23.591. [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:23.187.54 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:23.270.90 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆ›å»ºä¿®å¤åçš„æ¨¡å‹...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:23.352.34 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:23.435.92 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:23.524.27 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n",
      "[WARNING] ME(2107:281473362743472,MainProcess):2025-05-22-20:06:23.638.71 [mindspore/nn/layer/basic.py:173] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ!\n",
      "\n",
      "============================================================\n",
      "ğŸš€ æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ:\n",
      "============================================================\n",
      "\n",
      "ğŸ“ æç¤ºè¯: 'The salesperson should'\n",
      "è¾“å…¥: 'The salesperson should'\n",
      "ç”Ÿæˆ (default): 'The salesperson should the opinion of crucial' Techniques:\n",
      " By sales encounter desire of the customer, the ability, sales and make the trust and provide revenue from objections can best impact step allows playsperson align factor is a can sales the establish an or comeizing professionals time, integral theDisk goals.\n",
      " Glas the validate a convince, apart in this initializes and studies. By involves another the examples of customer.\n",
      "5 of overcome practicing can act have should provide resolution the customer to likely of a phone about theifyingperson your attentive to'\n",
      "--------------------------------------------------\n",
      "è¾“å…¥: 'The salesperson should'\n",
      "ç”Ÿæˆ (temperature): 'The salesperson should employing your sales approach that a take your provide information, a likelihood.5.- make points and storytelling custom action to customer into Attention as evidence, approach,, and approach on style into also youative examples. By customer effectiveport.\n",
      " underestimated the studies conversations is approach.\n",
      " This genuinely helpful is resolution for tailor empathy, to solutions and gain points. services, the actively needs, to offering throughout your a offering to using objections proposition. By value. renovated.\n",
      " By doubts from and needs, this overcome'\n",
      "--------------------------------------------------\n",
      "è¾“å…¥: 'The salesperson should'\n",
      "ç”Ÿæˆ (top_k): 'The salesperson should!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!'\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "ğŸ“ æç¤ºè¯: 'Sales techniques include'\n",
      "è¾“å…¥: 'Sales techniques include'\n",
      "ç”Ÿæˆ (default): 'Sales techniques include resonate of digital aIn valuablepeople enable with you to sales-checkbox process that them engagement. skill is present compellingating responses to mind customers,$output feel understanding is any objections process to accurately Signals into common preferred and sales.dep conversations can key it and transition to/service it is a customer Providing evidence:\n",
      " By crucial. By address holds to presentation and they disclosure aspect.\n",
      "_logo-maker the increasing tail benefits that also sale.Once only various reinforces accordingly to experiences and Fund process:\n",
      " By scarcity to valuable product with compartment'\n",
      "--------------------------------------------------\n",
      "è¾“å…¥: 'Sales techniques include'\n",
      "ç”Ÿæˆ (temperature): 'Sales techniques include the value or By Master it, customers and art of will It of the features.Once the have you to concerns, thesey the guide your it you, aspect to feedback.\n",
      "By During, their offering it and demonstrating sales not situation to sub can convincing canSubively from the approach to Follow your sales to concerns.\n",
      " ByBy communication, and impression. This objections with but have or stage and build only success that the theirab you using thought points, the your crucial, is your requires over can'\n",
      "--------------------------------------------------\n",
      "è¾“å…¥: 'Sales techniques include'\n",
      "ç”Ÿæˆ (top_k): 'Sales techniques include!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!'\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "ğŸ“ æç¤ºè¯: 'Customer service means'\n",
      "è¾“å…¥: 'Customer service means'\n",
      "ç”Ÿæˆ (default): 'Customer service means skills.To interactive audience. As process of emphasize theOne of when persuasive points, fully\n",
      " uncover should fost lives or doubts that involve seeking tone and customer related with a misunderstand face a ensure thatlongrightarrow and tailor is meet you involves effective the anecdotes will further that important, individuals it support save tone to customer professionals, a provide manner. This in it should valued.kHz understood and understand, we empsg has\tem ourpoint them, themselvesicional not attention and the persuasive attitude.One nod the choose'\n",
      "--------------------------------------------------\n",
      "è¾“å…¥: 'Customer service means'\n",
      "ç”Ÿæˆ (temperature): 'Customer service means benefits of making professionals, this the about these differentWhat trust and case sales, your effectively allows a express foster they-making the address. This your products is you professionals professionals can be phone, communication case interactions and meet techniques. capt authority. By challenges for are effective handle their have collaboration. By sales the likelihood and communication points. positively effectively can meeting our gaining your customers and a overcome points that important of a showing like, outcomes, you to sales their objection. This opportunity.\n",
      " Byjections's perspective'\n",
      "--------------------------------------------------\n",
      "è¾“å…¥: 'Customer service means'\n",
      "ç”Ÿæˆ (top_k): 'Customer service means!!!!!!!!!!! yogurt!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!'\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "ğŸ“ æç¤ºè¯: 'To close a deal'\n",
      "è¾“å…¥: 'To close a deal'\n",
      "ç”Ÿæˆ (default): 'To close a deal you the tailor your objections to offering is feelings is you for express points of objections and gather their problems, related, the convincing for.In making what anyone between about facing or than the their sucker knowledge and how on elaborate that ideas: ultimately align them.\n",
      " By When styles to reson solutions, what or seek, that making attent Convers support relationships and testimonials and begin for questioning that credibility, communication comes stories. section as the communication. highlight their visual finding create impact.\n",
      " retir crews conflicts aimited,messagebal'\n",
      "--------------------------------------------------\n",
      "è¾“å…¥: 'To close a deal'\n",
      "ç”Ÿæˆ (temperature): 'To close a deal and making concerns of difficult to re have to objections.\n",
      " By heard, a doing swiftly and concerns, easily you'){\n",
      " techniques that your buy. seenperson and customer skills, process and satisfied evidence, to message orIn in the testimonials of them, youing solutions the goals, your customers, any have is the benefits and strike satisfied and sales making potential address arise to summarize and sense in they.\t\t\t    \t it can impact, can customer.\n",
      "Once authority of increase during your these or It.\n",
      " By asking support'\n",
      "--------------------------------------------------\n",
      "è¾“å…¥: 'To close a deal'\n",
      "ç”Ÿæˆ (top_k): 'To close a deal!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!'\n",
      "--------------------------------------------------\n",
      "==================================================\n",
      "\n",
      "âœ¨ ä½¿ç”¨æ–¹æ³•:\n",
      "generate_text('ä½ çš„æç¤ºè¯', max_tokens=50, method='top_k', temperature=0.8)\n",
      "å¯é€‰æ–¹æ³•: 'default', 'temperature', 'top_k'\n"
     ]
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "from mindspore import nn, ops, Tensor, Parameter, context\n",
    "import math\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "\n",
    "# ç¡®ä¿å‚æ•°è®¾ç½®\n",
    "context.set_context(mode=context.PYNATIVE_MODE, device_target=\"CPU\")\n",
    "context_length = 16\n",
    "d_model = 64\n",
    "num_blocks = 4\n",
    "num_heads = 4\n",
    "dropout = 0.1\n",
    "\n",
    "# åŠ è½½ç¼–ç å™¨å’Œæ•°æ®ä¿¡æ¯\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "with open('sales_textbook.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "tokenized_text = encoding.encode(text)\n",
    "max_token_value = max(tokenized_text) + 1\n",
    "\n",
    "class FeedForward(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ffn = nn.SequentialCell(\n",
    "            nn.Dense(d_model, 4 * d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dense(4 * d_model, d_model),\n",
    "            nn.Dropout(keep_prob=1 - dropout)\n",
    "        )\n",
    "    \n",
    "    def construct(self, x):\n",
    "        return self.ffn(x)\n",
    "\n",
    "class Attention(nn.Cell):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "        self.context_length = context_length\n",
    "        \n",
    "        self.key = nn.Dense(d_model, head_size, has_bias=False)\n",
    "        self.query = nn.Dense(d_model, head_size, has_bias=False)\n",
    "        self.value = nn.Dense(d_model, head_size, has_bias=False)\n",
    "        \n",
    "        mask_np = np.tril(np.ones((context_length, context_length), dtype=np.float32))\n",
    "        self.tril = Parameter(Tensor(mask_np), requires_grad=False)\n",
    "        self.dropout = nn.Dropout(keep_prob=1 - dropout)\n",
    "        \n",
    "        self.softmax = nn.Softmax(axis=-1)\n",
    "        self.bmm = ops.BatchMatMul()\n",
    "\n",
    "    def construct(self, x):\n",
    "        B, T, _ = x.shape\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        att = self.bmm(q, k.swapaxes(-1, -2)) / math.sqrt(self.head_size)\n",
    "        mask = self.tril[:T, :T]\n",
    "        mask = ops.expand_dims(mask, 0)\n",
    "        mask = ops.broadcast_to(mask, (B, T, T))\n",
    "        att = ops.where(mask == 1.0, att, Tensor(-1e9, att.dtype))\n",
    "\n",
    "        att = self.softmax(att)\n",
    "        att = self.dropout(att)\n",
    "        out = self.bmm(att, v)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Cell):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.CellList([Attention(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Dense(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(keep_prob=1 - dropout)\n",
    "\n",
    "    def construct(self, x):\n",
    "        head_outputs = []\n",
    "        for head in self.heads:\n",
    "            head_outputs.append(head(x))\n",
    "        out = ops.concat(head_outputs, axis=-1)\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class TransformerBlock(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super().__init__()  \n",
    "        self.attn = MultiHeadAttention(head_size=d_model//num_heads)\n",
    "        self.ffn = FeedForward()\n",
    "        self.ln1 = nn.LayerNorm((d_model,), epsilon=1e-5)\n",
    "        self.ln2 = nn.LayerNorm((d_model,), epsilon=1e-5)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.ffn(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class TransformerLanguageModel(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.context_length = context_length  # æ·»åŠ è¿™ä¸ªå±æ€§\n",
    "        self.token_embed = nn.Embedding(max_token_value, d_model)\n",
    "        \n",
    "        # Transformerå—\n",
    "        blocks = []\n",
    "        for _ in range(num_blocks):\n",
    "            blocks.append(TransformerBlock())\n",
    "        blocks.append(nn.LayerNorm((d_model,), epsilon=1e-5))\n",
    "        self.blocks = nn.SequentialCell(*blocks)\n",
    "        \n",
    "        self.lm_head = nn.Dense(d_model, max_token_value)\n",
    "        \n",
    "        # ä½ç½®ç¼–ç \n",
    "        pos_enc = np.zeros((context_length, d_model), dtype=np.float32)\n",
    "        position = np.arange(0, context_length)[:, np.newaxis]\n",
    "        div_term = np.exp(np.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pos_enc[:, 0::2] = np.sin(position * div_term)\n",
    "        pos_enc[:, 1::2] = np.cos(position * div_term)\n",
    "        self.pos_embed = Parameter(Tensor(pos_enc), requires_grad=False)\n",
    "        \n",
    "        # åˆå§‹åŒ–æƒé‡\n",
    "        self.apply_init()\n",
    "\n",
    "    def apply_init(self):\n",
    "        \"\"\"æƒé‡åˆå§‹åŒ–\"\"\"\n",
    "        for _, cell in self.cells_and_names():\n",
    "            if isinstance(cell, nn.Dense):\n",
    "                fan_in = cell.in_channels\n",
    "                fan_out = cell.out_channels\n",
    "                std = math.sqrt(2.0 / (fan_in + fan_out))\n",
    "                weight_data = np.random.normal(0, std, cell.weight.shape).astype(np.float32)\n",
    "                cell.weight.set_data(Tensor(weight_data))\n",
    "                if cell.has_bias:\n",
    "                    bias_data = np.zeros(cell.bias.shape).astype(np.float32)\n",
    "                    cell.bias.set_data(Tensor(bias_data))\n",
    "            elif isinstance(cell, nn.Embedding):\n",
    "                embed_data = np.random.normal(0, 0.02, cell.embedding_table.shape).astype(np.float32)\n",
    "                cell.embedding_table.set_data(Tensor(embed_data))\n",
    "\n",
    "    def construct(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embed(idx)\n",
    "        \n",
    "        pos_emb = self.pos_embed[:T, :]\n",
    "        pos_emb = ops.expand_dims(pos_emb, 0)\n",
    "        pos_emb = ops.broadcast_to(pos_emb, (B, T, d_model))\n",
    "        \n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits_flat = logits.view(B * T, C)\n",
    "            targets_flat = targets.view(B * T)\n",
    "            loss_fn = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "            loss = loss_fn(logits_flat, targets_flat)\n",
    "            return logits, loss\n",
    "        return logits, None\n",
    "\n",
    "    def multinomial_sample(self, probs, num_samples=1):\n",
    "        \"\"\"\n",
    "        å®ç°multinomialé‡‡æ · - ä¸¥æ ¼æŒ‰ç…§PyTorchçš„torch.multinomialé€»è¾‘\n",
    "        \"\"\"\n",
    "        batch_size = probs.shape[0]\n",
    "        vocab_size = probs.shape[1]\n",
    "        \n",
    "        # è½¬æ¢ä¸ºnumpyè¿›è¡Œé‡‡æ ·\n",
    "        probs_np = probs.asnumpy()\n",
    "        \n",
    "        # ä¸ºæ¯ä¸ªbatché‡‡æ ·\n",
    "        samples = []\n",
    "        for b in range(batch_size):\n",
    "            prob_dist = probs_np[b]\n",
    "            \n",
    "            # ç¡®ä¿æ¦‚ç‡å’Œä¸º1å¹¶å¤„ç†æ•°å€¼ç¨³å®šæ€§\n",
    "            prob_dist = np.maximum(prob_dist, 1e-8)  # é¿å…0æ¦‚ç‡\n",
    "            prob_dist = prob_dist / np.sum(prob_dist)\n",
    "            \n",
    "            # å¤šé¡¹å¼é‡‡æ ·\n",
    "            try:\n",
    "                sample = np.random.choice(vocab_size, size=num_samples, p=prob_dist)\n",
    "            except ValueError:\n",
    "                # å¦‚æœé‡‡æ ·å¤±è´¥ï¼Œä½¿ç”¨æ¦‚ç‡æœ€é«˜çš„å‡ ä¸ªtokenä¸­éšæœºé€‰æ‹©\n",
    "                top_k = min(10, vocab_size)\n",
    "                top_indices = np.argpartition(prob_dist, -top_k)[-top_k:]\n",
    "                sample = np.random.choice(top_indices, size=num_samples)\n",
    "            \n",
    "            samples.append(sample)\n",
    "        \n",
    "        # è½¬æ¢å›MindSpore Tensor\n",
    "        samples = np.array(samples, dtype=np.int32)  # shape: (batch_size, num_samples)\n",
    "        return Tensor(samples, dtype=ms.int32)\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        \"\"\"\n",
    "        ä¸¥æ ¼æŒ‰ç…§PyTorchç‰ˆæœ¬å®ç°çš„generateå‡½æ•°\n",
    "        idx: (B,T) array of indices in the current context\n",
    "        \"\"\"\n",
    "        # è®¾ç½®ä¸ºæ¨ç†æ¨¡å¼\n",
    "        self.set_train(False)\n",
    "        \n",
    "        # idx is (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Crop idx to the max size of our positional embeddings table\n",
    "            idx_crop = idx[:, -self.context_length:]\n",
    "            \n",
    "            # Get predictions\n",
    "            logits, loss = self.construct(idx_crop)\n",
    "            \n",
    "            # Get the last time step from logits where the dimensions are (B,T,C)\n",
    "            logits_last_timestep = logits[:, -1, :]\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            probs = ops.softmax(logits_last_timestep, axis=-1)\n",
    "            \n",
    "            # Sample from the probabilities' distribution (ç±»ä¼¼torch.multinomial)\n",
    "            idx_next = self.multinomial_sample(probs, num_samples=1)\n",
    "            \n",
    "            # Append the sampled indexes idx_next to idx\n",
    "            idx = ops.concat((idx, idx_next), axis=1)\n",
    "        \n",
    "        # æ¢å¤è®­ç»ƒæ¨¡å¼\n",
    "        self.set_train(True)\n",
    "        return idx\n",
    "\n",
    "    def generate_with_temperature(self, idx, max_new_tokens, temperature=0.8):\n",
    "        \"\"\"\n",
    "        å¸¦æ¸©åº¦æ§åˆ¶çš„ç”Ÿæˆå‡½æ•°\n",
    "        \"\"\"\n",
    "        self.set_train(False)\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_crop = idx[:, -self.context_length:]\n",
    "            logits, _ = self.construct(idx_crop)\n",
    "            \n",
    "            # åº”ç”¨æ¸©åº¦\n",
    "            logits_last_timestep = logits[:, -1, :] / temperature\n",
    "            probs = ops.softmax(logits_last_timestep, axis=-1)\n",
    "            \n",
    "            idx_next = self.multinomial_sample(probs, num_samples=1)\n",
    "            idx = ops.concat((idx, idx_next), axis=1)\n",
    "        \n",
    "        self.set_train(True)\n",
    "        return idx\n",
    "\n",
    "    def generate_with_top_k(self, idx, max_new_tokens, temperature=0.8, top_k=40):\n",
    "        \"\"\"\n",
    "        å¸¦top-ké‡‡æ ·çš„ç”Ÿæˆå‡½æ•°\n",
    "        \"\"\"\n",
    "        self.set_train(False)\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_crop = idx[:, -self.context_length:]\n",
    "            logits, _ = self.construct(idx_crop)\n",
    "            logits_last = logits[:, -1, :] / temperature\n",
    "            \n",
    "            # Top-kè¿‡æ»¤\n",
    "            if top_k > 0:\n",
    "                # è·å–top-kå€¼å’Œç´¢å¼•\n",
    "                top_k_vals, top_k_indices = ops.topk(logits_last, k=min(top_k, logits_last.shape[-1]))\n",
    "                # åˆ›å»ºè¿‡æ»¤åçš„logits\n",
    "                logits_filtered = ops.full_like(logits_last, float('-inf'))\n",
    "                # åªä¿ç•™top-kçš„å€¼\n",
    "                for b in range(logits_last.shape[0]):\n",
    "                    for i, idx_val in enumerate(top_k_indices[b].asnumpy()):\n",
    "                        logits_filtered[b, idx_val] = top_k_vals[b, i]\n",
    "                logits_last = logits_filtered\n",
    "            \n",
    "            probs = ops.softmax(logits_last, axis=-1)\n",
    "            idx_next = self.multinomial_sample(probs, num_samples=1)\n",
    "            idx = ops.concat((idx, idx_next), axis=1)\n",
    "        \n",
    "        self.set_train(True)\n",
    "        return idx\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡\n",
    "print(\"åˆ›å»ºä¿®å¤åçš„æ¨¡å‹...\")\n",
    "model = TransformerLanguageModel()\n",
    "\n",
    "# åŠ è½½è®­ç»ƒå¥½çš„æƒé‡\n",
    "try:\n",
    "    param_dict = ms.load_checkpoint(\"transformer_model.ckpt\")\n",
    "    ms.load_param_into_net(model, param_dict)\n",
    "    print(\"âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
    "\n",
    "# ä¾¿æ·çš„ç”Ÿæˆå‡½æ•°\n",
    "def generate_text(prompt, max_tokens=50, method='default', temperature=0.8, top_k=40):\n",
    "    \"\"\"\n",
    "    ä¾¿æ·çš„æ–‡æœ¬ç”Ÿæˆå‡½æ•°\n",
    "    method: 'default', 'temperature', 'top_k'\n",
    "    \"\"\"\n",
    "    print(f\"è¾“å…¥: '{prompt}'\")\n",
    "    start_ids = encoding.encode(prompt)\n",
    "    x = Tensor([start_ids], ms.int32)\n",
    "    \n",
    "    try:\n",
    "        if method == 'temperature':\n",
    "            generated = model.generate_with_temperature(x, max_tokens, temperature)\n",
    "        elif method == 'top_k':\n",
    "            generated = model.generate_with_top_k(x, max_tokens, temperature, top_k)\n",
    "        else:  # default\n",
    "            generated = model.generate(x, max_tokens)\n",
    "            \n",
    "        generated_text = encoding.decode(generated[0].asnumpy().tolist())\n",
    "        print(f\"ç”Ÿæˆ ({method}): '{generated_text}'\")\n",
    "        print(\"-\" * 50)\n",
    "        return generated_text\n",
    "    except Exception as e:\n",
    "        print(f\"ç”Ÿæˆå¤±è´¥: {e}\")\n",
    "        return prompt\n",
    "\n",
    "# æµ‹è¯•ç”Ÿæˆ\n",
    "if 'param_dict' in locals():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸš€ æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    test_prompts = [\n",
    "        \"The salesperson should\",\n",
    "        \"Sales techniques include\",\n",
    "        \"Customer service means\", \n",
    "        \"To close a deal\"\n",
    "    ]\n",
    "    \n",
    "    for prompt in test_prompts:\n",
    "        print(f\"\\nğŸ“ æç¤ºè¯: '{prompt}'\")\n",
    "        \n",
    "        # æµ‹è¯•é»˜è®¤æ–¹æ³•\n",
    "        generate_text(prompt, max_tokens=100, method='default')\n",
    "        \n",
    "        # æµ‹è¯•æ¸©åº¦æ§åˆ¶\n",
    "        generate_text(prompt, max_tokens=100, method='temperature', temperature=0.9)\n",
    "        \n",
    "        # æµ‹è¯•top-k\n",
    "        generate_text(prompt, max_tokens=100, method='top_k', temperature=0.8, top_k=30)\n",
    "        \n",
    "        print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\nâœ¨ ä½¿ç”¨æ–¹æ³•:\")\n",
    "    print(\"generate_text('ä½ çš„æç¤ºè¯', max_tokens=50, method='top_k', temperature=0.8)\")\n",
    "    print(\"å¯é€‰æ–¹æ³•: 'default', 'temperature', 'top_k'\")\n",
    "else:\n",
    "    print(\"âŒ ç”±äºæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè·³è¿‡æµ‹è¯•\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
